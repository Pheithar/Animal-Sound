{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "\tgbifID\n",
      "\tidentifier\n",
      "\tspecies\n",
      "\tgenus\n",
      "\tfamily\n",
      "\tclass\n",
      "\tphylum\n",
      "\tfile_name\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"../datasets/AnimalSoundFull.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"Columns:\\n\\t\" + \"\\n\\t\".join(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate ids, if splitting occurs\n",
    "# def uniqueIDGenerator() -> int:\n",
    "#     cnt = 0\n",
    "#     while True:\n",
    "#         yield cnt\n",
    "#         cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_p = Path(\"../data\")\n",
    "spec_p = Path(\"../spectrograms/full_dataset/images\")\n",
    "current_spectograms = os.listdir(spec_p)\n",
    "\n",
    "\n",
    "def generateSpectogram(row):\n",
    "    if f\"{row['gbifID']}.jpg\" in current_spectograms:\n",
    "        return\n",
    "    if \"foo\" in row.file_name:\n",
    "        return\n",
    "\n",
    "    # Waveform, samplerate\n",
    "    try:\n",
    "        wav, sr = torchaudio.load(sound_p / row.file_name)\n",
    "    except:\n",
    "        return\n",
    "\n",
    "    n_fft = 1024\n",
    "    win_length = None\n",
    "    hop_length = 512\n",
    "    n_mels = 128\n",
    "\n",
    "    mel = T.MelSpectrogram(\n",
    "        sample_rate  = sr,\n",
    "        n_fft        = n_fft,\n",
    "        win_length   = win_length,\n",
    "        hop_length   = hop_length,\n",
    "        center       = True,\n",
    "        pad_mode     = \"reflect\",\n",
    "        power        = 2.0,\n",
    "        norm         = \"slaney\",\n",
    "        onesided     = True,\n",
    "        n_mels       = n_mels,\n",
    "        mel_scale    = \"htk\"\n",
    "    )\n",
    "\n",
    "    melspec = mel(wav)[0]\n",
    "\n",
    "    height = 128 * 2\n",
    "    width = height * 4\n",
    "    dpi = 100\n",
    "    \n",
    "    fig = plt.figure(frameon=False, figsize=(width/dpi, height/dpi), dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "\n",
    "    im = ax.imshow(librosa.power_to_db(melspec), origin=\"lower\", aspect=\"auto\")\n",
    "\n",
    "    filename = spec_p / f\"{row['gbifID']}.jpg\"\n",
    "\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "    return row\n",
    "\n",
    "# samples = df.sample(10, random_state=10000).apply(generateSpectogram, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "formats: can't open input file `../data/Chordata/Aves/Sylviidae/Sylvia/Sylvia_atricapilla/779866917.mp3': \n",
      "formats: can't open input file `../data/Chordata/Aves/Threskiornithidae/Threskiornis/Threskiornis_aethiopicus/1229954416.mp3': \n",
      "/home/snoooze/Git/Animal-Sound/venv/lib/python3.9/site-packages/torchaudio/functional/functional.py:594: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
      "  warnings.warn(\n",
      "/home/snoooze/Git/Animal-Sound/venv/lib/python3.9/site-packages/torchaudio/functional/functional.py:594: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
      "  warnings.warn(\n",
      "formats: can't open input file `../data/Chordata/Aves/Fringillidae/Chloris/Chloris_chloris/779849992.mp3': \n",
      "/home/snoooze/Git/Animal-Sound/venv/lib/python3.9/site-packages/torchaudio/functional/functional.py:594: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Creating dask dataframe\n",
    "ddf = dd.from_pandas(df, npartitions=16)\n",
    "\n",
    "res = ddf.map_partitions(lambda df: df.apply((lambda row: generateSpectogram(row)), axis=1)).compute(scheduler=get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had: 3 files that couldnt be opened\n",
      "(16172, 8) (16169, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Had: {df.shape[0] - len(os.listdir(spec_p))} files that couldnt be opened\")\n",
    "current_spectograms = os.listdir(spec_p)\n",
    "\n",
    "\n",
    "new_df = df[df.apply(lambda x: True if f\"{x.gbifID}.jpg\" in current_spectograms else False, axis=1)]\n",
    "\n",
    "print(df.shape, new_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../spectrograms/full_dataset/images/../full_dataset_df.csv')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.to_csv(spec_p / \"../full_dataset_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ecd0e996f407c2311e17c22dcf8da616d53766a30a4c3d5d57f043990f40fdd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
