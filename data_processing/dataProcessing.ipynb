{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Processing\n",
    "\n",
    "The first step in data processing is obtaining and preparing the data. We used the Animal Sound Archive, it is available in the folder `animal-sound`.\n",
    "\n",
    "As one can see, there are many files in that folder. The relevants files are `occurrence.txt` and `multimedia.txt`. The first has information about each ocurrence, and the second has the links to the audio files."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import dask.dataframe as dd\r\n",
    "from dask.multiprocessing import get\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "\r\n",
    "import requests\r\n",
    "\r\n",
    "import os\r\n",
    "import shutil\r\n",
    "\r\n",
    "import librosa\r\n",
    "\r\n",
    "import warnings\r\n",
    "\r\n",
    "import torchaudio\r\n",
    "import torchaudio.transforms as T\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import warnings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merging dataframes\n",
    "\n",
    "Before anything else, we have to merge the relevant data in the files."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ocurrences = pd.read_csv(\"../animal-sound/occurrence.txt\",\r\n",
    "                         delimiter=\"\\t\")\r\n",
    "ocurrences.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the `ocurrences.txt` file has a lot of columns, and most of them are filled with `NaN`. We have to get only the columns that are relevant to the problem: \n",
    " - **gbifID**\n",
    " - **species**\n",
    " - **genus**\n",
    " - **family**\n",
    " - **class**\n",
    " - **phylum**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ocurrences = ocurrences[[\"gbifID\", \"species\", \"genus\", \"family\", \"class\", \"phylum\"]]\r\n",
    "ocurrences.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "multimedia = pd.read_csv(\"../animal-sound/multimedia.txt\",\r\n",
    "                         delimiter=\"\\t\")\r\n",
    "multimedia.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `multimedia.txt` file has irrelevant columns. We only need the **gbifID** and **identifier** columns. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "multimedia = multimedia[[\"gbifID\", \"identifier\"]]\r\n",
    "multimedia.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have to combine the 2 datasets merging them by the **gbifID**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = multimedia.merge(ocurrences, on=\"gbifID\", how=\"inner\")\r\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next step is to remove the samples with `NaN` in any column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = df.dropna()\r\n",
    "df.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download the audios\n",
    "\n",
    "Now that we have all the links of the audios, we have to save them."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tqdm.pandas(desc=\"Downloading files\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def createAudioFile(row):\r\n",
    "  ocurr_id = str(row[\"gbifID\"])\r\n",
    "  phylum = row[\"phylum\"]\r\n",
    "  class_name = row[\"class\"]\r\n",
    "  family = row[\"family\"]\r\n",
    "  genus = row[\"genus\"]\r\n",
    "  species = row[\"species\"]\r\n",
    "  url = row[\"identifier\"]\r\n",
    "  \r\n",
    "  folder = '{}/{}/{}/{}/{}/'.format(phylum, class_name, family, genus, species).replace(\" \", \"_\")\r\n",
    "  \r\n",
    "  file_name = folder + ocurr_id + \".mp3\"\r\n",
    "  folder_name = r\"../data/{}\".format(folder)\r\n",
    "\r\n",
    "  if not os.path.exists('../data/' + folder):\r\n",
    "    os.makedirs(folder_name, exist_ok=True)\r\n",
    "\r\n",
    "  path = r\"../data/{}\".format(file_name)\r\n",
    "    \r\n",
    "  if not os.path.exists(path):\r\n",
    "    with open(path, \"wb\") as f:\r\n",
    "      f.write(requests.get(url).content)\r\n",
    "    \r\n",
    "  return file_name\r\n",
    "\r\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creating dask dataframe\r\n",
    "ddf = dd.from_pandas(df, npartitions=16)\r\n",
    "\r\n",
    "# df[\"file_name\"] = df.progress_apply(createAudioFile, axis=1)\r\n",
    "res = ddf.map_partitions(lambda df: df.apply((lambda row: createAudioFile(row)), axis=1)).compute(scheduler=get)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have to remove corrupted data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tqdm.pandas(desc=\"Dropping corrupted files\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def isCorrupted(row):\r\n",
    "  try:\r\n",
    "    with warnings.catch_warnings():\r\n",
    "      warnings.simplefilter(\"ignore\")\r\n",
    "      torchaudio.load(\"../data/\" + row.file_name)\r\n",
    "      return False\r\n",
    "  except:\r\n",
    "    return True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df[\"is_corrupted\"] = df.progress_apply(isCorrupted, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = df.drop(df[df.is_corrupted].index).drop(columns=\"is_corrupted\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finaly, we save the file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = df.reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.to_csv(\"../datasets/AnimalSoundFull.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "05ec5b253bfbbd0f3665b561f42f8ff4c11567d04d42cfb2c6dadb81cf478878"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}